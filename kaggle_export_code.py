"""
CODE NÃ€Y DÃ™NG Äá»‚ THÃŠM VÃ€O CUá»I NOTEBOOK KAGGLE
Copy toÃ n bá»™ code dÆ°á»›i Ä‘Ã¢y vÃ  paste vÃ o cuá»‘i file training trÃªn Kaggle
"""

# ============================================================
# EXPORT MODELS CHO á»¨NG Dá»¤NG DEPLOYMENT
# ThÃªm Ä‘oáº¡n code nÃ y vÃ o CUá»I file training trÃªn Kaggle
# ============================================================

print("\n" + "="*60)
print("ğŸ“¦ XUáº¤T MODELS Äá»‚ Sá»¬ Dá»¤NG TRONG á»¨NG Dá»¤NG PRODUCTION")
print("="*60)

import pickle
import json
from tensorflow.keras.applications import EfficientNetB0

# --- 1. LÆ¯U TOKENIZER ---
print("\n1ï¸âƒ£ Äang lÆ°u Tokenizer...")
tokenizer_path = '/kaggle/working/tokenizer.pkl'
with open(tokenizer_path, 'wb') as f:
    pickle.dump(tokenizer, f)
print(f"   âœ“ ÄÃ£ lÆ°u: {tokenizer_path}")
print(f"   âœ“ Vocab size: {len(tokenizer.word_index)}")

# --- 2. KIá»‚M TRA FULL MODEL ---
print("\n2ï¸âƒ£ Kiá»ƒm tra Full Model...")
# Model nÃ y Ä‘Ã£ Ä‘Æ°á»£c lÆ°u tá»± Ä‘á»™ng trong quÃ¡ trÃ¬nh training
model_path = '/kaggle/working/best_model_captioning.h5'
if os.path.exists(model_path):
    print(f"   âœ“ Full model Ä‘Ã£ cÃ³: {model_path}")
    print(f"   âœ“ File size: {os.path.getsize(model_path) / (1024*1024):.2f} MB")
else:
    print("   âš ï¸ KhÃ´ng tÃ¬m tháº¥y model, Ä‘ang lÆ°u model hiá»‡n táº¡i...")
    model.save(model_path)
    print(f"   âœ“ ÄÃ£ lÆ°u: {model_path}")

# --- 3. Táº O ENCODER RIÃŠNG (CNN Feature Extractor) ---
print("\n3ï¸âƒ£ Äang táº¡o CNN Encoder riÃªng...")
encoder_path = '/kaggle/working/efficientnet_encoder.h5'
try:
    # Load EfficientNetB0 giá»‘ng nhÆ° trong training
    encoder_model = EfficientNetB0(
        weights='imagenet',
        include_top=False,
        pooling='avg'  # Output: (None, 1280)
    )
    encoder_model.save(encoder_path)
    print(f"   âœ“ ÄÃ£ lÆ°u encoder: {encoder_path}")
    print(f"   âœ“ Output shape: {encoder_model.output_shape}")
    print(f"   âœ“ File size: {os.path.getsize(encoder_path) / (1024*1024):.2f} MB")
except Exception as e:
    print(f"   âš ï¸ Lá»—i khi lÆ°u encoder: {e}")

# --- 4. LÆ¯U METADATA (ThÃ´ng tin quan trá»ng) ---
print("\n4ï¸âƒ£ Äang lÆ°u Metadata...")
metadata = {
    # Model architecture
    'model_type': 'EfficientNetB0 + Bidirectional LSTM',
    'encoder': 'EfficientNetB0',
    'decoder': 'Bidirectional LSTM',
    
    # Parameters
    'vocab_size': vocab_size,
    'max_length': max_length,
    'image_size': IMG_SIZE,  # 224
    'feature_dim': 1280,  # EfficientNetB0 output
    'lstm_units': 512,  # BiLSTM(256) * 2
    'embedding_dim': 256,
    
    # Tokens
    'start_token': 'startseq',
    'end_token': 'endseq',
    'pad_token': '<pad>',
    
    # Training info
    'dataset': 'Flickr8k',
    'epochs_trained': EPOCHS,
    'batch_size': BATCH_SIZE,
    
    # Usage info
    'preprocessing': 'ImageNet normalization (mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])',
    'inference_method': 'Beam Search (k=3)'
}

metadata_path = '/kaggle/working/model_metadata.json'
with open(metadata_path, 'w') as f:
    json.dump(metadata, f, indent=2)
print(f"   âœ“ ÄÃ£ lÆ°u metadata: {metadata_path}")

# --- 5. Táº O README CHO MODELS ---
print("\n5ï¸âƒ£ Äang táº¡o README...")
readme_content = f"""# Image Captioning Models - Export tá»« Kaggle

## ThÃ´ng tin Models

### 1. Tokenizer (tokenizer.pkl)
- Vocab size: {vocab_size}
- Max length: {max_length}
- Start token: 'startseq'
- End token: 'endseq'

### 2. Full Model (best_model_captioning.h5)
- Architecture: EfficientNetB0 + Bidirectional LSTM
- Input: Image features (1280,) + Text sequence
- Output: Word probabilities (vocab_size,)

### 3. CNN Encoder (efficientnet_encoder.h5)
- Architecture: EfficientNetB0 (pretrained ImageNet)
- Input: Image (224, 224, 3)
- Output: Features (1280,)

### 4. Metadata (model_metadata.json)
- Chá»©a táº¥t cáº£ thÃ´ng tin cáº¥u hÃ¬nh

## CÃ¡ch sá»­ dá»¥ng

### BÆ°á»›c 1: Download files
Download táº¥t cáº£ 4 files tá»« Kaggle Output:
1. tokenizer.pkl
2. best_model_captioning.h5
3. efficientnet_encoder.h5
4. model_metadata.json

### BÆ°á»›c 2: Äáº·t vÃ o thÆ° má»¥c models/
```
models/
â”œâ”€â”€ tokenizer.pkl
â”œâ”€â”€ decoder_model.h5 (rename tá»« best_model_captioning.h5)
â”œâ”€â”€ encoder_model.h5 (rename tá»« efficientnet_encoder.h5)
â””â”€â”€ model_metadata.json
```

### BÆ°á»›c 3: Cháº¡y á»©ng dá»¥ng
```bash
cd backend
python main.py
```

## Preprocessing Image

```python
from tensorflow.keras.applications.efficientnet import preprocess_input
import numpy as np

# Load vÃ  resize
image = load_img(path, target_size=(224, 224))
image = img_to_array(image)

# Normalize
image = preprocess_input(image)  # ImageNet normalization
image = np.expand_dims(image, axis=0)

# Extract features
features = encoder.predict(image)  # Shape: (1, 1280)
```

## Inference (Beam Search)

Xem code trong `backend/src/caption_generator.py`

---
Created: {pd.Timestamp.now()}
Dataset: Flickr8k
Training epochs: {EPOCHS}
"""

readme_path = '/kaggle/working/MODELS_README.md'
with open(readme_path, 'w') as f:
    f.write(readme_content)
print(f"   âœ“ ÄÃ£ táº¡o README: {readme_path}")

# --- 6. Tá»”NG Káº¾T ---
print("\n" + "="*60)
print("âœ… HOÃ€N Táº¤T EXPORT!")
print("="*60)
print("\nğŸ“¦ CÃC FILE Cáº¦N DOWNLOAD:")
print("   1. tokenizer.pkl")
print("   2. best_model_captioning.h5")
print("   3. efficientnet_encoder.h5")
print("   4. model_metadata.json")
print("   5. MODELS_README.md (optional)")

print("\nğŸ“ Vá»Š TRÃ:")
print("   â†’ Kaggle â†’ Output section â†’ Click Download")

print("\nğŸ“ SAU KHI DOWNLOAD:")
print("   1. Äáº·t vÃ o thÆ° má»¥c: d:\\LSTM_APP\\models\\")
print("   2. Rename best_model_captioning.h5 â†’ decoder_model.h5")
print("   3. Rename efficientnet_encoder.h5 â†’ encoder_model.h5")
print("   4. Cháº¡y: python test_models.py")
print("   5. Cháº¡y app: python backend/main.py")

print("\nğŸ‰ Sáºµn sÃ ng Ä‘á»ƒ deploy!")
print("="*60)

# Hiá»ƒn thá»‹ chi tiáº¿t files
print("\nğŸ“Š CHI TIáº¾T FILES:")
for filename in ['tokenizer.pkl', 'best_model_captioning.h5', 
                 'efficientnet_encoder.h5', 'model_metadata.json', 
                 'MODELS_README.md']:
    filepath = f'/kaggle/working/{filename}'
    if os.path.exists(filepath):
        size_mb = os.path.getsize(filepath) / (1024 * 1024)
        print(f"   âœ“ {filename:30s} - {size_mb:6.2f} MB")
    else:
        print(f"   âœ— {filename:30s} - NOT FOUND")
